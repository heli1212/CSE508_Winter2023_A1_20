{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "import pickle\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Lower characters\n",
    "def lowerChar(ip):\n",
    "    s=\"\"\n",
    "    for ch in ip:\n",
    "        ch=ch.lower()\n",
    "        s+=ch\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Remove Stop words\n",
    "\n",
    "def removeStopwords(temp):\n",
    "    stoWords=set(stopwords.words('english'))\n",
    "    s=\"\"\n",
    "    ans=[]\n",
    "    for h in temp:\n",
    "        if not h in stoWords:\n",
    "            ans.append(h)\n",
    "    return ans "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------TOKENIZATION-----------------------------#\n",
    "\n",
    "def tokenize_ipStr(ip):   \n",
    "    temp=word_tokenize(ip)\n",
    "    return temp  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Remove Punctuations\n",
    "def removePuntuations(ip):\n",
    "    test_str = ip.translate(str.maketrans('', '', string.punctuation))\n",
    "    return test_str\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Remove White Spaces\n",
    "def removeWS(ip):\n",
    "    s1=\" \".join(ip.split())\n",
    "    return s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preprocessing\n",
    "def preprocess(ip):\n",
    "    # call lower function\n",
    "    s=lowerChar(ip)\n",
    "    s=removePuntuations(s)\n",
    "    s=removeWS(s)\n",
    "    # call tokenize file function\n",
    "    temp = tokenize_ipStr(s)\n",
    "    #Call remove Stop words funtions\n",
    "    #print(\"\\n\\n\\n\")\n",
    "    s=removeStopwords(temp)\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### AND Function\n",
    "\n",
    "def andFunc(l1,l2):\n",
    "    lenl1 = len(l1)\n",
    "    lenl2 = len(l2)\n",
    "    i=0\n",
    "    j=0\n",
    "    ansList = []\n",
    "    cmprs = 0\n",
    "    while(i<lenl1 and j<lenl2):\n",
    "        if(l1[i] == l2[j]):\n",
    "            ansList.append(l1[i])\n",
    "            i=i+1\n",
    "            j=j+1\n",
    "        elif(l1[i] < l2[j]):\n",
    "            i=i+1\n",
    "        else:\n",
    "            j=j+1\n",
    "\n",
    "        cmprs=cmprs + 1\n",
    "\n",
    "    return ansList,cmprs ##### MERGING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Bigram Inverted Index from pickle #####\n",
    "\n",
    "def bigramInvIndex():\n",
    "    with open('D:/SEMESTER-2/IR-Ass1/file_bigrams.pkl', 'rb') as file:\n",
    "        \n",
    "        # Call load method to deserialze\n",
    "        dict = pickle.load(file)\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Positional Inverted Index from pickle #######\n",
    "\n",
    "def positionalInvIndex():\n",
    "    with open('D:/SEMESTER-2/IR-Ass1/file_positional.pkl', 'rb') as file:\n",
    "        \n",
    "        # Call load method to deserialze\n",
    "        myvar = pickle.load(file)\n",
    "    return myvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "doctIdDict={}\n",
    "for i in range(1,1401):\n",
    "    s=\"\"\n",
    "    if(i>=1 and i<=9):\n",
    "        s=\"000\"\n",
    "    elif(i>=10 and i<=99):\n",
    "        s=\"00\"\n",
    "    if(i>=100 and i<=999):\n",
    "        s=\"0\"\n",
    "    text=\"cranfield\"+s+\"{x}\".format(x=i)\n",
    "    doctIdDict[i]=text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### User Input ###########\n",
    "\n",
    "sss=[\"null\"]\n",
    "def userInput(queryCount):\n",
    "\n",
    "    print(\"Enter Query: \")\n",
    "    ip = input()\n",
    "    sss[0]=ip\n",
    "    ans_temp = preprocess(ip) ##### Preprocess\n",
    "    \n",
    "    ans=[]\n",
    "\n",
    "    for i in range(0,len(ans_temp)-1):\n",
    "        ans.append(ans_temp[i]+\" \"+ans_temp[i+1])\n",
    "    \n",
    "    print(\"Tokens :\", ans)\n",
    "    ans_list=[]\n",
    "    dict = bigramInvIndex()\n",
    "    if(len(ans)==0):\n",
    "        ans_list=[]\n",
    "    elif(len(ans)==1):\n",
    "        if dict.get(ans[0]) is not None:\n",
    "            ans_list=dict[ans[0]]\n",
    "        else:\n",
    "            ans_list=[]\n",
    "\n",
    "    else:\n",
    "        for i in range(0,len(ans)-1):\n",
    "            word1=ans[i]\n",
    "            word2=ans[i+1]\n",
    "            comp=0\n",
    "            opList=[]\n",
    "            if dict.get(word1) is not None:\n",
    "                list1=dict[word1]\n",
    "            else:\n",
    "                list1 = []\n",
    "            if dict.get(word2) is not None:\n",
    "                list2=dict[word2]\n",
    "            else:\n",
    "                list2 = []\n",
    "\n",
    "            if(len(ans_list)!=0):\n",
    "                list1=ans_list\n",
    "            opList,cmpr=andFunc(list1, list2)\n",
    "            ans_list=opList\n",
    "\n",
    "    ## Doc Names ##\n",
    "    ans_doc_name=[]\n",
    "    for i in ans_list:\n",
    "        ans_doc_name.append(doctIdDict[i])\n",
    "    ans_doc_name2=[]\n",
    "    # for i in ans_list2:\n",
    "    #     ans_doc_name2.append(doctIdDict[i])\n",
    "        \n",
    "    ######## Output #########\n",
    "    queryCount=queryCount+1\n",
    "    print(\"No of documents retrieved for query \"+str(queryCount)+\" using bigram inverted index: \", len(ans_list))\n",
    "    print(\"Names of document retrieved for query \"+str(queryCount)+\" using bigram inverted index: \",ans_doc_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def userIP(queryCount):\n",
    "    posDict = positionalInvIndex()\n",
    "    s=sss[0]\n",
    "    token=preprocess(s)\n",
    "    common_docs=[]\n",
    "    for i in range(0,len(token)-1):\n",
    "        if posDict.get(token[i]) is not None:\n",
    "            temp_list1=posDict[token[i]]\n",
    "        else:\n",
    "            temp_list1=[{}]\n",
    "        if posDict.get(token[i+1]) is not None:\n",
    "            temp_list2=posDict[token[i+1]]\n",
    "        else:\n",
    "            temp_list2=[{}]\n",
    "        temp_dict1=temp_list1[0]\n",
    "        temp_dict2=temp_list2[0]\n",
    "\n",
    "        if(len(common_docs)==0):\n",
    "            list1=list(temp_dict1.keys())\n",
    "        else:\n",
    "            list1=common_docs\n",
    "        list2=list(temp_dict2.keys())\n",
    "        ansList=andFunc(list1,list2)\n",
    "        common_docs=ansList[0]\n",
    "        \n",
    "    \n",
    "    documents=[]\n",
    "    doc=0\n",
    "    for index in common_docs:\n",
    "        ans_temp_list=[]\n",
    "        for i in range(0,len(token)-1):\n",
    "            temp_list1=posDict[token[i]]\n",
    "            temp_list2=posDict[token[i+1]]\n",
    "            temp_dict1=temp_list1[0]\n",
    "            temp_dict2=temp_list2[0]\n",
    "            if (len(ans_temp_list)==0):\n",
    "                posList1=temp_dict1[index]\n",
    "            else:\n",
    "                posList1=ans_temp_list\n",
    "            posList2=temp_dict2[index]\n",
    "        \n",
    "            temp_list=[]\n",
    "            for x in posList1:\n",
    "                for y in posList2:\n",
    "                    if x+1==y:\n",
    "                        temp_list.append(y)\n",
    "           \n",
    "            if(len(temp_list)==0):\n",
    "                ans_temp_list=temp_list\n",
    "                break\n",
    "            else:\n",
    "                ans_temp_list=temp_list\n",
    "        if(len(ans_temp_list)!=0):\n",
    "            doc=doc+1\n",
    "            documents.append(doctIdDict[index])\n",
    "            \n",
    "            \n",
    "\n",
    "    queryCount=queryCount+1\n",
    "    print(\"No of documents retrieved for query \"+str(queryCount)+\" using positional inverted index: \", doc)\n",
    "    print(\"Names of document retrieved for query \"+str(queryCount)+\" using positional inverted index: \",documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Query: \n",
      "Tokens : ['wave boundary', 'boundary layer']\n",
      "No of documents retrieved for query 1 using bigram inverted index:  3\n",
      "Names of document retrieved for query 1 using bigram inverted index:  ['cranfield0002', 'cranfield0309', 'cranfield0569']\n",
      "No of documents retrieved for query 1 using positional inverted index:  2\n",
      "Names of document retrieved for query 1 using positional inverted index:  ['cranfield0002', 'cranfield0309']\n",
      "Enter Query: \n",
      "Tokens : ['curved shock', 'shock wave']\n",
      "No of documents retrieved for query 2 using bigram inverted index:  2\n",
      "Names of document retrieved for query 2 using bigram inverted index:  ['cranfield0002', 'cranfield0401']\n",
      "No of documents retrieved for query 2 using positional inverted index:  1\n",
      "Names of document retrieved for query 2 using positional inverted index:  ['cranfield0002']\n"
     ]
    }
   ],
   "source": [
    "n=int(input(\"Enter number of queries: \"))\n",
    "for i in range (n):\n",
    "    userInput(i)\n",
    "    userIP(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "56c95f378ea2e5388ed1e4c2901bc417243c2d63860c7da449c286d31346d8d3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
