{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "import pickle\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Lower characters\n",
    "def lowerChar(ip):\n",
    "    s=\"\"\n",
    "    for ch in ip:\n",
    "        ch=ch.lower()\n",
    "        s+=ch\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------TOKENIZATION-----------------------------#\n",
    "\n",
    "def tokenize_ipStr(ip):   \n",
    "    temp=word_tokenize(ip)\n",
    "    return temp  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Remove Stop words\n",
    "\n",
    "def removeStopwords(temp):\n",
    "    stoWords=set(stopwords.words('english'))\n",
    "    s=\"\"\n",
    "    ans=[]\n",
    "    for h in temp:\n",
    "        if not h in stoWords:\n",
    "            ans.append(h)\n",
    "    return ans "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Remove Punctuations\n",
    "def removePuntuations(ip):\n",
    "    test_str = ip.translate(str.maketrans('', '', string.punctuation))\n",
    "    return test_str\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Remove White Spaces\n",
    "def removeWS(ip):\n",
    "    s1=\" \".join(ip.split())\n",
    "    return s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preprocessing\n",
    "def preprocess(ip):\n",
    "    # call lower function\n",
    "    s=lowerChar(ip)\n",
    "    s=removePuntuations(s)\n",
    "    s=removeWS(s)\n",
    "    # call tokenize file function\n",
    "    temp = tokenize_ipStr(s)\n",
    "    #Call remove Stop words funtions\n",
    "    #print(\"\\n\\n\\n\")\n",
    "    s=removeStopwords(temp)\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### OR Function \n",
    "def orFunc(l1,l2):\n",
    "    lenl1 = len(l1)\n",
    "    lenl2 = len(l2)\n",
    "    i=0\n",
    "    j=0\n",
    "    ansList = []\n",
    "    cmprs = 0\n",
    "    while(i<lenl1 and j<lenl2):\n",
    "        if(l1[i] == l2[j]):\n",
    "            ansList.append(l1[i])\n",
    "            i=i+1\n",
    "            j=j+1\n",
    "        elif(l1[i] < l2[j]):\n",
    "            ansList.append(l1[i])\n",
    "            i=i+1\n",
    "        else:\n",
    "            ansList.append(l2[j])\n",
    "            j=j+1\n",
    "\n",
    "        cmprs=cmprs + 1\n",
    "\n",
    "    while(i<lenl1):\n",
    "        ansList.append(l1[i])\n",
    "        i=i+1\n",
    "    while(j<lenl2):\n",
    "        ansList.append(l2[j])\n",
    "        j=j+1\n",
    "        \n",
    "    return ansList,cmprs ##### MERGING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### AND Function\n",
    "\n",
    "def andFunc(l1,l2):\n",
    "    lenl1 = len(l1)\n",
    "    lenl2 = len(l2)\n",
    "    i=0\n",
    "    j=0\n",
    "    ansList = []\n",
    "    cmprs = 0\n",
    "    while(i<lenl1 and j<lenl2):\n",
    "        if(l1[i] == l2[j]):\n",
    "            ansList.append(l1[i])\n",
    "            i=i+1\n",
    "            j=j+1\n",
    "        elif(l1[i] < l2[j]):\n",
    "            i=i+1\n",
    "        else:\n",
    "            j=j+1\n",
    "\n",
    "        cmprs=cmprs + 1\n",
    "\n",
    "    return ansList,cmprs ##### MERGING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### NOT Func\n",
    "\n",
    "def notFunc(list):\n",
    "    ansList = []\n",
    "    cmprs=0\n",
    "    for i in range(1,1401):\n",
    "        if i not in list:\n",
    "            ansList.append(i)\n",
    "\n",
    "    return ansList,cmprs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### AND NOT Function\n",
    "\n",
    "def andNot(l1,l2):\n",
    "    tempList = notFunc(l2)\n",
    "    ansList,cmprs = andFunc(l1,tempList)\n",
    "    return ansList,cmprs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OR NOT Function\n",
    "\n",
    "def orNot(l1,l2):\n",
    "    tempList = notFunc(l2)\n",
    "    ansList,cmprs = orFunc(l1,tempList)\n",
    "    return ansList,cmprs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Unigram inverted index ##########\n",
    "\n",
    "def unigramInvIndex():\n",
    "    with open('D:/SEMESTER-2/IR-Ass1/file.pkl', 'rb') as file:\n",
    "        \n",
    "        # Call load method to deserialze\n",
    "        myvar = pickle.load(file)\n",
    "  \n",
    "    return myvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "doctIdDict={}\n",
    "for i in range(1,1401):\n",
    "    s=\"\"\n",
    "    if(i>=1 and i<=9):\n",
    "        s=\"000\"\n",
    "    elif(i>=10 and i<=99):\n",
    "        s=\"00\"\n",
    "    if(i>=100 and i<=999):\n",
    "        s=\"0\"\n",
    "    text=\"cranfield\"+s+\"{x}\".format(x=i)\n",
    "    doctIdDict[i]=text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### User Input ###########\n",
    "\n",
    "def userInput():\n",
    "    print(\"Enter Query: \")\n",
    "    ip = input()\n",
    "    ans = preprocess(ip) ##### Preprocess\n",
    "    print(\"Enter {temp} Operations: \".format(temp=len(ans)-1))\n",
    "    operList=[]\n",
    "    for i in range(0,len(ans)-1):\n",
    "        op=input()\n",
    "        operList.append(op)\n",
    "    print(\"Tokens :\", ans)\n",
    "    print(\"Operations: \",operList)\n",
    "\n",
    "    total_comp=0\n",
    "    ans_list=[]\n",
    "    dict = unigramInvIndex()\n",
    "    for i in range(0,len(ans)-1):\n",
    "        op=operList[i]\n",
    "        word1=ans[i]\n",
    "        word2=ans[i+1]\n",
    "        comp=0\n",
    "        opList=[]\n",
    "        if dict.get(word1) is not None:\n",
    "            list1=dict[word1]\n",
    "        else:\n",
    "            list1 = []\n",
    "        if dict.get(word2) is not None:\n",
    "            list2=dict[word2]\n",
    "        else:\n",
    "            list2 = []\n",
    "\n",
    "        ##### Query Oprations #######\n",
    "        if op == \"OR\":\n",
    "            if(len(ans_list)!=0):\n",
    "                list1=ans_list\n",
    "            opList,cmpr=orFunc(list1, list2)\n",
    "            ans_list=opList\n",
    "            comp+=cmpr\n",
    "        elif op == \"AND\":\n",
    "            if(len(ans_list)!=0):\n",
    "                list1=ans_list\n",
    "            opList,cmpr=andFunc(list1, list2)\n",
    "            ans_list=opList\n",
    "            comp+=cmpr\n",
    "        elif op == \"OR NOT\":\n",
    "            if(len(ans_list)!=0):\n",
    "                list1=ans_list\n",
    "            opList,cmpr=orNot(list1, list2)\n",
    "            ans_list=opList\n",
    "            comp+=cmpr\n",
    "        elif op == \"AND NOT\":\n",
    "            if(len(ans_list)!=0):\n",
    "                list1=ans_list\n",
    "            opList,cmpr=andNot(list1, list2)\n",
    "            ans_list=opList\n",
    "            comp+=cmpr\n",
    "        total_comp+=comp\n",
    "\n",
    "    ## Query ##\n",
    "    ip_format=\"\"\n",
    "    for i in range(0,len(ans)-1):\n",
    "        ip_format+=ans[i]+\" \"+operList[i]+\" \"\n",
    "    ip_format+=ans[len(ans)-1]\n",
    "\n",
    "    ## Doc Names ##\n",
    "    ans_doc_name=[]\n",
    "    for i in ans_list:\n",
    "        ans_doc_name.append(doctIdDict[i])\n",
    "\n",
    "    ######## Output #########\n",
    "    \n",
    "    print(\"Query : \",ip_format)\n",
    "    print(\"No of documents retrieved: \", len(ans_list))\n",
    "    print(\"Names of document retrieved: \",ans_doc_name)\n",
    "    print(\"Minimum Number comaparisons required: \", total_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Query: \n",
      "Enter 2 Operations: \n",
      "Tokens : ['experimental', 'solutions', 'slipstram']\n",
      "Operations:  ['AND', 'OR']\n",
      "Query :  experimental AND solutions OR slipstram\n",
      "No of documents retrieved:  20\n",
      "Names of document retrieved:  ['cranfield0047', 'cranfield0188', 'cranfield0329', 'cranfield0435', 'cranfield0467', 'cranfield0498', 'cranfield0518', 'cranfield0576', 'cranfield0644', 'cranfield0663', 'cranfield0717', 'cranfield0753', 'cranfield0767', 'cranfield0823', 'cranfield1074', 'cranfield1078', 'cranfield1083', 'cranfield1185', 'cranfield1214', 'cranfield1352']\n",
      "Minimum Number comaparisons required:  421\n"
     ]
    }
   ],
   "source": [
    "n=int(input(\"Enter number of queries: \"))\n",
    "for i in range (n):\n",
    "    userInput()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "56c95f378ea2e5388ed1e4c2901bc417243c2d63860c7da449c286d31346d8d3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
